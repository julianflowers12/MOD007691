---
title: "guardian"
author: "Julian Flowers"
date: "22/01/2022"
output: html_document
params:
   search: "face masks pollution"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE) 
library(myScrapers)

library(pacman)
p_load(quanteda.textmodels, quanteda.textstats, guardianapi, myScrapers, lubridate, tidyverse)
pacman::p_load_gh("trinker/entity")
```



## search Guardian for articles on `r params$search`

## reads open data platform


```{r}


guardianapi::gu_api_key(check_env = TRUE)


last_month <- guardianapi::gu_content(query = params$search, from_date = today() - days(365), to_date = today())

last_month_articles <- last_month %>%
  mutate(date = ymd(str_sub(web_publication_date, 1, 10))) %>%
  select(date, web_title, headline, short_url, section_name) %>%
  DT::datatable(extensions = "Buttons", 
                escape = FALSE, 
                options = list(
                  dom = "Bfrtip", 
                  buttons = c("csv", "excel"), 
                  pageLength = 50
                ))

last_month_articles
```

```{r}

pqs <- function(start_date, dept = "health and social care"){
  if(!require(hansard))devtools::install_github("EvanOdell/hansard")
  require(hansard)
  require(dplyr)
  require(tibble)

  cat("Please wait...")
  
  dhsc2018 <- hansard_all_answered_questions(start_date = start_date, answering_body = dept) 
  health_qn <- dhsc2018 %>%
    select(answer_date = date_of_answer_value, question_text,  answer_text = answer_text_value, answering_member = answering_member_printed_value,
                  hansard_category = hansard_heading_value) %>%
             mutate(answer_text = str_remove(answer_text, "\\<p\\>"))
  health_qn %>%
    as_tibble()
  
}

pq_ppe <- pqs(start_date = as.Date("2020-01-01"), "health and social care") %>%
  filter(str_detect(hansard_category, "NHS: Protective Clothing")) %>%
  select(-answering_member)

pq_ppe %>%
  filter(str_detect(answer_text, "plastic")) %>%
  reactable::reactable(searchable = TRUE, sortable = TRUE)


rb <- hansard::hansard_research_briefings()
  
hcb_pp <- rb %>%
  filter(str_detect(title, "[Pp]lastic"))

hcb_pp %>%
  unnest("section", names_repair = "universal") %>%
  unnest("topic")

rb %>%
  filter(str_detect(title, "Mask"))

```

## Speeches

```{r}

library(data.table)
library(readr)
library(stringr)
library(dplyr)

speeches <- fread("~/Dropbox/My Mac (Julians-MBP-2)/Downloads/hansard-speeches-v310.csv")



head(speeches)

speeches[year == 2021, .N, by = .(major_heading)][order(-N)]
pp <- speeches[year >= 2020 & str_detect(speech, "PPE"), ][]

pp[, .N, by = .(minor_heading)][order(-N)]
pp_ppe <- pp[str_detect(minor_heading, "PPE")|str_detect(minor_heading, "Personal Protective Equipment"), ][,date := janitor::excel_numeric_to_date(as.numeric(date)) ][order(desc(date))]

```

```{r}

plot(money_entity(pp_ppe$speech))
  



```


```{r}

library(quanteda)

pp %>%
  count(display_as, party, minor_heading)

corpus <- corpus(pp_ppe, text_field = "speech")


tokens <- quanteda::tokens(corpus, remove_punct = TRUE) %>%
  tokens_remove(stopwords()) %>%
  tokens_ngrams(n = 1:2)

kwic(tokens, "items", window = 10)

dfm <- dfm(tokens)
  
topfeatures(dfm, 500)

```

## Plastic and microplastics and health

```{r}

toks_pp <- pp %>%
  corpus(text_field = "speech") %>%
  tokens(char_tolower("word")) %>%
  tokens_remove(stopwords()) 

fcm <- fcm(toks_pp)


```

```{r}





```
